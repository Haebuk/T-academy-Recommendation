{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys, gc \n",
    "from plotnine import *\n",
    "import plotnine\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib as mpl\n",
    "from matplotlib import rc\n",
    "import re\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import datetime\n",
    "from math import log # IDF 계산을 위해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/User/Documents/T아카데미/T 아카데미/input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_json : json 형태의 파일을 dataframe 형태로 불러오는 코드 \n",
    "magazine = pd.read_json(path + 'magazine.json', lines=True) # lines = True : Read the file as a json object per line.\n",
    "metadata = pd.read_json(path + 'metadata.json', lines=True)\n",
    "users = pd.read_json(path + 'users.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ccfcfc4def5401eac5fa6cc73ebe4ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3624), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 25 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import itertools\n",
    "from itertools import chain\n",
    "import glob\n",
    "import os \n",
    "\n",
    "input_read_path = path + 'read/read/'\n",
    "# os.listdir : 해당 경로에 있는 모든 파일들을 불러오는 명령어 \n",
    "file_list = os.listdir(input_read_path)\n",
    "exclude_file_lst = ['read.tar', '.2019010120_2019010121.un~']\n",
    "\n",
    "read_df_list = []\n",
    "for file in tqdm_notebook(file_list):\n",
    "    # 예외처리 \n",
    "    if file in exclude_file_lst:\n",
    "        continue \n",
    "    else:\n",
    "        file_path = input_read_path + file\n",
    "        df_temp = pd.read_csv(file_path, header=None, names=['raw'])\n",
    "        # file명을 통해서 읽은 시간을 추출(from, to)\n",
    "        df_temp['from'] = file.split('_')[0]\n",
    "        df_temp['to'] = file.split('_')[1]\n",
    "        read_df_list.append(df_temp)\n",
    "    \n",
    "read_df = pd.concat(read_df_list)\n",
    "# reads 파일을 전처리해서 row 당 user - article이 1:1이 되도록 수정 \n",
    "read_df['user_id'] = read_df['raw'].apply(lambda x: x.split(' ')[0])\n",
    "read_df['article_id'] = read_df['raw'].apply(lambda x: x.split(' ')[1:])\n",
    "\n",
    "def chainer(s):\n",
    "    return list(itertools.chain.from_iterable(s))\n",
    "\n",
    "read_cnt_by_user = read_df['article_id'].map(len)\n",
    "read_rowwise = pd.DataFrame({'from': np.repeat(read_df['from'], read_cnt_by_user),\n",
    "                             'to': np.repeat(read_df['to'], read_cnt_by_user),\n",
    "                             'user_id': np.repeat(read_df['user_id'], read_cnt_by_user),\n",
    "                             'article_id': chainer(read_df['article_id'])})\n",
    "\n",
    "read_rowwise.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "\n",
    "metadata['reg_datetime'] = metadata['reg_ts'].apply(lambda x : datetime.fromtimestamp(x/1000.0))\n",
    "metadata.loc[metadata['reg_datetime'] == metadata['reg_datetime'].min(), 'reg_datetime'] = datetime(2090, 12, 31)\n",
    "metadata['reg_dt'] = metadata['reg_datetime'].dt.date\n",
    "metadata['type'] = metadata['magazine_id'].apply(lambda x : '개인' if x == 0.0 else '매거진')\n",
    "metadata['reg_dt'] = pd.to_datetime(metadata['reg_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_rowwise = read_rowwise.merge(metadata[['id', 'reg_dt']], how='left', left_on='article_id', right_on='id')\n",
    "read_rowwise = read_rowwise[read_rowwise['article_id'] != '']\n",
    "\n",
    "# 사용자가 읽은 글의 목록들을 저장 \n",
    "read_total = pd.DataFrame(read_rowwise.groupby(['user_id'])['article_id'].unique()).reset_index()\n",
    "read_total.columns = ['user_id', 'article_list']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 콘텐츠 기반의 추천시스템\n",
    "- Model의 단어를 이용한 방식\n",
    "- TF-IDF 형식\n",
    "    - index : 문서의 아이디 \n",
    "    - column : 단어 \n",
    "\n",
    "하지만, 문서가 총 64만개로 너무 많고 data.0의 파일을 읽어보면 단어 또한 너무 많아서 사용하기가 어려운 상황\n",
    "\n",
    "### 해결방식\n",
    "위와 같은 문제를 해결하기 위해서 해당 대회의 1등팀인 NAFMA팀은 글의 키워드를 활용해서 Embedding을 구성 \n",
    "- 참고자료 : https://github.com/JungoKim/brunch_nafma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "metadata = metadata[metadata['keyword_list'].notnull()].reset_index()\n",
    "metadata = metadata[metadata['reg_dt'] >= '2019-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "article2idx = {}\n",
    "for i, l in enumerate(metadata['id'].unique()):\n",
    "    article2idx[l] = i\n",
    "    \n",
    "idx2article = {i: item for item, i in article2idx.items()}\n",
    "articleidx = metadata['articleidx'] = metadata['id'].apply(lambda x: article2idx[x]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "docs = metadata['keyword_list'].apply(lambda x: ' '.join(x)).values\n",
    "tfidv = TfidfVectorizer(use_idf=True, smooth_idf=False, norm=None).fit(docs)\n",
    "tfidv_df = scipy.sparse.csr_matrix(tfidv.transform(docs))\n",
    "tfidv_df = tfidv_df.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73574, 20823)\n"
     ]
    }
   ],
   "source": [
    "print(tfidv_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 Sparse 형태인 것을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 메모리 문제 발생 \n",
    "cos_sim = cosine_similarity(tfidv_df, tfidv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = pd.read_csv(path + '/predict/predict/dev.users', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0e0231ff444e1c8c2715679ccf8542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 2min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "popular_rec_model = read_rowwise['article_id'].value_counts().index[0:100]\n",
    "\n",
    "top_n = 100\n",
    "with open('./recommend.txt', 'w') as f:\n",
    "    for user in tqdm_notebook(valid[0].values):\n",
    "        seen = chainer(read_total[read_total['user_id'] == user]['article_list'])\n",
    "        for seen_id in seen:\n",
    "            # 2019년도 이전에 읽어서 혹은 메타데이터에 글이 없어서 유사도 계산이 안된 글\n",
    "            cos_sim_sum = np.zeros(len(cos_sim))\n",
    "            try:\n",
    "                cos_sim_sum += cos_sim[article2idx[seen_id]]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        recs = []\n",
    "        for rec in cos_sim_sum.argsort()[-(top_n+100):][::-1]:\n",
    "            if (idx2article[rec] not in seen) & (len(recs) < 100):\n",
    "                recs.append(idx2article[rec])\n",
    "\n",
    "        f.write('%s %s\\n' % (user, ' '.join(recs[0:100])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/choco9966/T-academy-Recommendation/blob/master/figure/Contents_Based_Score.PNG?raw=true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
